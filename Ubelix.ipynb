{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ubelix.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TillVollmer5/Semester_Project_DSF_J.Lorenzetti_T.Vollmer/blob/main/Ubelix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ubelix 1\n",
        "This notebook section documents the process of running a *Hello world* python script on Ubelix.\n",
        "\n",
        "logging into ubelix with campus account via ssh (using Anaconda Powershell Prompt, PuTTY did not work) with ssh username.submit.unibe.ch and the corresponding password\n",
        "\n",
        "call editor on linux and open a job submission file with nano hello-world.sh\n",
        "\n",
        "write the script below into the hello-world.sh file (script from https://hpc-unibe-ch.github.io/quick-start.html)\n",
        "save file with CTRL-O\n"
      ],
      "metadata": {
        "id": "dpUjiKW_ppti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash \n",
        "#SBATCH --ntasks=1 \n",
        "#SBATCH --cpus-per-task=1\n",
        "#SBATCH --mem-per-cpu=1GB\n",
        "\n",
        "module load Workspace_Home\n",
        "mkdir -p $SCRATCH/hello-world\n",
        "cd $SCRATCH/hello-world\n",
        "echo \"Hello, UBELIX from node $(hostname)\" > hello-world.txt"
      ],
      "metadata": {
        "id": "OFKireXICQiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "submit the job with sbatch hello-world.sh\n",
        "an identification number for the job is obtained (submitted batch job ID)\n",
        "\n",
        "job can be monitored with squeue --job=jobID, which gives information on the state of the job (running, pending..) and how long it has been running for\n",
        "\n",
        "command ls is used to check for output files (slurm-jobID.out). If there was an error while executing the job, the error is specified within these files. To find the output of the hello world job, the directory needs to be changed to /scratch/hello-world. The hello-world.txt file can then be transferred to the local workstation with FileZilla."
      ],
      "metadata": {
        "id": "-QAGWzb2CWeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output in the hello-world.txt file\n",
        "Hello, UBELIX from node bnode002"
      ],
      "metadata": {
        "id": "M7X_SSBTEe1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ubelix 2\n",
        "This notebook section displays the process of the creating the production MD (on CPU and GPU)."
      ],
      "metadata": {
        "id": "4RxcFAkeqCy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the files needed for the production run were transferred to the Ubelix home directory using Filezilla. This included the .top, .cpt, and .gro files produced in the MD tutorial as well as the script needed for the actual processing (md.mdp).\n",
        "The jobs for the production MD are basically run in the same way as the hello world task. Small changes were made to the instructions: memory was set to 16GB and estimated duration to 1 hour. The module GROMACS is loaded before executing the production run."
      ],
      "metadata": {
        "id": "XB4Fa7VxC3PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "#SBATCH --ntasks=1\n",
        "#SBATCH --time=01:00:00\n",
        "#SBATCH --mem-per-cpu=16GB\n",
        "\n",
        "module load Workspace_Home\n",
        "module load GROMACS\n",
        "gmx grompp -f md.mdp -c npt.gro -t npt.cpt -p topol.top -o md_0_1.tpr\n",
        "gmx mdrun -deffnm md_0_1"
      ],
      "metadata": {
        "id": "J4tyQuifDshm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the script above gave output files named md_0_1, however, they could not be processed during the following steps of the tutorial. Upon inspection of the slurm-jobID.out file, it was evident that a fatal error occurred. This also explains why the job only ran for a few minutes. The source of this error probably lies within the installation of GROMACS on Ubelix.\n",
        "\n",
        "When running the job on the other CPU called bdw, an error occurred right after submission, namely that the gmx command was unknown. The same happened with the use of GPU."
      ],
      "metadata": {
        "id": "EzQ6V14oFwIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "#SBATCH --ntasks=1\n",
        "#SBATCH --time=00:30:00\n",
        "#SBATCH --mem-per-cpu=16GB\n",
        "#SBATCH --partition=bdw\n",
        "\n",
        "module load Workspace_Home\n",
        "module load GROMACS\n",
        "gmx grompp -f md.mdp -c npt.gro -t npt.cpt -p topol.top -o md_0_1.tpr\n",
        "gmx mdrun -deffnm md_0_1"
      ],
      "metadata": {
        "id": "utm0qIYjG6_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "#SBATCH --ntasks=1\n",
        "#SBATCH --time=00:30:00\n",
        "#SBATCH --mem-per-cpu=16GB\n",
        "#SBATCH --partition=gpu\n",
        "\n",
        "module load Workspace_Home\n",
        "module load GROMACS\n",
        "gmx grompp -f md.mdp -c npt.gro -t npt.cpt -p topol.top -o md_0_1.tpr\n",
        "gmx mdrun -deffnm md_0_1 -nb gpu\n"
      ],
      "metadata": {
        "id": "gECdVuBhqZuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to these errors, the production MD could not be performed on Ubelix and the different CPU's and GPU could not be compared. To solve the problem, GROMACS would probably need to be reinstalled either on the personal home directory or for everyone on the entire cluster."
      ],
      "metadata": {
        "id": "vjW7pjsrHUGh"
      }
    }
  ]
}